{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b06fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gym[box2d] pyglet "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388c4c60",
   "metadata": {},
   "source": [
    "# Important Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c3b55b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\abdul\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym \n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.logger import configure\n",
    "from stable_baselines3.common.vec_env import VecTransposeImage\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498f37fe",
   "metadata": {},
   "source": [
    "# Creating Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a28a2d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name=\"CarRacing-v2\"\n",
    "env=gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d689ef9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment_ID    : CarRacing-v2\n",
      "Action_Space      : Box([-1.  0.  0.], 1.0, (3,), float32)\n",
      "Observation_space : Box(0, 255, (96, 96, 3), uint8) \n",
      "It is an image with 0-255 brightness and shape of (96, 96, 3)\n",
      "Reward_range      : (-inf, inf)\n",
      "Render_mode       : None\n",
      "Shape_of_Reset    : (96, 96, 3)\n",
      "Reward_threshold  : 900\n",
      "Max_episode_steps : 1000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Environment_ID    : {env.spec.id}\")\n",
    "print(f\"Action_Space      : {env.action_space}\")\n",
    "print(f\"Observation_space : {env.observation_space} \\nIt is an image with 0-255 brightness and shape of {env.reset()[0].shape}\")  \n",
    "print(f\"Reward_range      : {env.reward_range}\")\n",
    "print(f\"Render_mode       : {env.render_mode}\")\n",
    "print(f\"Shape_of_Reset    : {env.reset()[0].shape}\")\n",
    "print(f\"Reward_threshold  : {env.spec.reward_threshold}\")\n",
    "print(f\"Max_episode_steps : {env.spec.max_episode_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e13032",
   "metadata": {},
   "source": [
    "# BASELINE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03e40b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 Score :- -437.0000000000054\n",
      "Episode 1 Score :- -876.3157894737926\n",
      "Baseline of model after 2 Episodes\n",
      "Average Score after 2 episodes : -656.657894736899 \n",
      "Our Model should score above -656.657894736899\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# env=gym.make(\"CarRacing-v2\",render_mode=\"human\")  # Render\n",
    "env=gym.make(\"CarRacing-v2\")\n",
    "num_episodes=2\n",
    "total_score=[]\n",
    "for episode in range(num_episodes):\n",
    "    state=env.reset()\n",
    "    done=False\n",
    "    score=0\n",
    "    while not done:\n",
    "#         env.render()\n",
    "        action=env.action_space.sample()\n",
    "        next_state,reward,done,info,_=env.step(action)\n",
    "        state=next_state\n",
    "        score+=reward\n",
    "    total_score.append(score)\n",
    "    print(f\"Episode {episode} Score :- {score}\")\n",
    "env.close()\n",
    "print(f\"Baseline of model after {num_episodes} Episodes\")\n",
    "print(f\"Average Score after {num_episodes} episodes : {sum(total_score)/num_episodes} \")\n",
    "print(f\"Our Model should score above {sum(total_score)/num_episodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "18f4cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c02d3",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "287ee151",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path=r\"C:\\Users\\abdul\\Downloads\\PROJECTS\\RL_PROJECTS\\Self_Driving_Car_RL\\Training\\Logs\"\n",
    "save_path=r\"C:\\Users\\abdul\\Downloads\\PROJECTS\\RL_PROJECTS\\Self_Driving_Car_RL\\Training\\Models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74daf4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=gym.make(\"CarRacing-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b9e5739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to C:\\Users\\abdul\\Downloads\\PROJECTS\\RL_PROJECTS\\Self_Driving_Car_RL\\Training\\Logs\n"
     ]
    }
   ],
   "source": [
    "# set up logger\n",
    "new_logger = configure(log_path, [\"stdout\", \"csv\", \"tensorboard\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be83a962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "env=gym.make(\"CarRacing-v2\")\n",
    "model=PPO(\"CnnPolicy\",env=env,verbose=1,tensorboard_log=log_path,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c16342a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold=900, verbose=1)\n",
    "eval_callback = EvalCallback(env, \n",
    "                             callback_on_new_best=stop_callback, \n",
    "                             eval_freq=10000, \n",
    "                             best_model_save_path=save_path, \n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97411ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -58.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015192537 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.14       |\n",
      "|    explained_variance   | 0.0442      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0804      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 0.955       |\n",
      "|    value_loss           | 0.336       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -55.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016729454 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.11       |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0176      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 0.95        |\n",
      "|    value_loss           | 0.304       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -58.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013657983 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.09       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0651      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 0.945       |\n",
      "|    value_loss           | 0.327       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -60.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 399         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021514058 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.08       |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0441      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 0.942       |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -60.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 511         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013988087 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.07       |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0404      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 0.942       |\n",
      "|    value_loss           | 0.272       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1b693d80190>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_logger(new_logger)\n",
    "model.learn(total_timesteps=10000,callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6a7d15",
   "metadata": {},
   "source": [
    "# TensorBoard Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de7bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard --logdir C:\\Users\\abdul\\Downloads\\PROJECTS\\RL_PROJECTS\\Self_Driving_Car_RL\\Training\\Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b427899a",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "401cd396",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4708700",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a47fd",
   "metadata": {},
   "source": [
    "# Loading Model Trained on 2M tirals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e87ee060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== CURRENT SYSTEM INFO ==\n",
      "- OS: Windows-10-10.0.22631-SP0 10.0.22631\n",
      "- Python: 3.9.18\n",
      "- Stable-Baselines3: 2.2.1\n",
      "- PyTorch: 2.1.1+cpu\n",
      "- GPU Enabled: False\n",
      "- Numpy: 1.26.2\n",
      "- Cloudpickle: 3.0.0\n",
      "- Gymnasium: 0.28.1\n",
      "- OpenAI Gym: 0.26.1\n",
      "\n",
      "== SAVED MODEL SYSTEM INFO ==\n",
      "- OS: Windows-10-10.0.22631-SP0 10.0.22631\n",
      "- Python: 3.9.18\n",
      "- Stable-Baselines3: 2.2.1\n",
      "- PyTorch: 2.1.1+cpu\n",
      "- GPU Enabled: False\n",
      "- Numpy: 1.26.2\n",
      "- Cloudpickle: 3.0.0\n",
      "- Gymnasium: 0.28.1\n",
      "- OpenAI Gym: 0.26.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym \n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.vec_env import VecTransposeImage\n",
    "path=r\"C:\\Users\\abdul\\Downloads\\PROJECTS\\RL_PROJECTS\\Self_Driving_Car_RL\\Training\\PPO_2m_Driving_model.zip\"\n",
    "env=gym.make(\"CarRacing-v2\")\n",
    "env=Monitor(env)\n",
    "env=DummyVecEnv([lambda:env])\n",
    "env=VecTransposeImage(env)\n",
    "model=PPO.load(path,env=env,print_system_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a70ad637",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d63d1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_2\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 998      |\n",
      "|    ep_rew_mean     | 725      |\n",
      "| time/              |          |\n",
      "|    fps             | 72       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 47104    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 998        |\n",
      "|    ep_rew_mean          | 731        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 69         |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10053707 |\n",
      "|    clip_fraction        | 0.527      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.77      |\n",
      "|    explained_variance   | 0.646      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.749      |\n",
      "|    n_updates            | 9940       |\n",
      "|    policy_gradient_loss | 0.00308    |\n",
      "|    std                  | 1.26       |\n",
      "|    value_loss           | 3.53       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 998         |\n",
      "|    ep_rew_mean          | 736         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.068569034 |\n",
      "|    clip_fraction        | 0.446       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.76       |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.676       |\n",
      "|    n_updates            | 9950        |\n",
      "|    policy_gradient_loss | 0.0121      |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 5.08        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 998        |\n",
      "|    ep_rew_mean          | 744        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 152        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10849034 |\n",
      "|    clip_fraction        | 0.49       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.75      |\n",
      "|    explained_variance   | 0.878      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.661      |\n",
      "|    n_updates            | 9960       |\n",
      "|    policy_gradient_loss | 0.00808    |\n",
      "|    std                  | 1.25       |\n",
      "|    value_loss           | 8          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 998        |\n",
      "|    ep_rew_mean          | 741        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 193        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06520416 |\n",
      "|    clip_fraction        | 0.441      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.74      |\n",
      "|    explained_variance   | 0.937      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.11       |\n",
      "|    n_updates            | 9970       |\n",
      "|    policy_gradient_loss | 0.00571    |\n",
      "|    std                  | 1.24       |\n",
      "|    value_loss           | 4.47       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 998       |\n",
      "|    ep_rew_mean          | 740       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 52        |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 235       |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1031347 |\n",
      "|    clip_fraction        | 0.51      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.74     |\n",
      "|    explained_variance   | 0.915     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.999     |\n",
      "|    n_updates            | 9980      |\n",
      "|    policy_gradient_loss | 0.00495   |\n",
      "|    std                  | 1.25      |\n",
      "|    value_loss           | 7.3       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 998        |\n",
      "|    ep_rew_mean          | 745        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 277        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12965512 |\n",
      "|    clip_fraction        | 0.541      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.74      |\n",
      "|    explained_variance   | 0.902      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.382      |\n",
      "|    n_updates            | 9990       |\n",
      "|    policy_gradient_loss | -0.00518   |\n",
      "|    std                  | 1.25       |\n",
      "|    value_loss           | 5.84       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 998        |\n",
      "|    ep_rew_mean          | 748        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 324        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07458886 |\n",
      "|    clip_fraction        | 0.521      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.74      |\n",
      "|    explained_variance   | 0.868      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.14       |\n",
      "|    n_updates            | 10000      |\n",
      "|    policy_gradient_loss | 0.0214     |\n",
      "|    std                  | 1.25       |\n",
      "|    value_loss           | 4.7        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 998       |\n",
      "|    ep_rew_mean          | 744       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 50        |\n",
      "|    iterations           | 9         |\n",
      "|    time_elapsed         | 368       |\n",
      "|    total_timesteps      | 63488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0749639 |\n",
      "|    clip_fraction        | 0.489     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.74     |\n",
      "|    explained_variance   | 0.913     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.36      |\n",
      "|    n_updates            | 10010     |\n",
      "|    policy_gradient_loss | 0.0109    |\n",
      "|    std                  | 1.25      |\n",
      "|    value_loss           | 8.69      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 998        |\n",
      "|    ep_rew_mean          | 747        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 49         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 411        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15447998 |\n",
      "|    clip_fraction        | 0.51       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.76      |\n",
      "|    explained_variance   | 0.923      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.953      |\n",
      "|    n_updates            | 10020      |\n",
      "|    policy_gradient_loss | 0.0134     |\n",
      "|    std                  | 1.26       |\n",
      "|    value_loss           | 9.36       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x26d7d494130>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000,reset_num_timesteps=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64cb225",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "482c5ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=gym.make(\"CarRacing-v2\",render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2e519f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward :-  [860.1593554615974, 759.9348765835166]\n",
      "Std Reward :-  [1000, 1000]\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward=evaluate_policy(model,env=env,n_eval_episodes=2,render=False,return_episode_rewards=True)\n",
    "print(\"Mean Reward :- \",mean_reward)\n",
    "print(\"Std Reward :- \",std_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "96f565f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3135fa5f",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f7673b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env=gym.make(\"CarRacing-v2\")\n",
    "env=gym.make(\"CarRacing-v2\",render_mode=\"human\") #render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ae24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes=1\n",
    "total_score=[]\n",
    "for episode in range(num_episodes):\n",
    "    score=0\n",
    "    state=env.reset()[0]\n",
    "    done=False\n",
    "    score=0\n",
    "    while not done:\n",
    "#         env.render()\n",
    "        action = model.predict(state)[0]\n",
    "        next_state,reward,done,info,_ = env.step(action)\n",
    "        score += reward\n",
    "        state = next_state\n",
    "    total_score.append(score)\n",
    "    print(f\"Episode {episode+1} Score :- {score}\")\n",
    "print(f\"Average Score after {num_episodes} episodes :- {sum(total_score)/num_episodes} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d2e97e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aae80a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4165d74a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
